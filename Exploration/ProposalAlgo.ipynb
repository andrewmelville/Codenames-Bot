{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb28dafa-752d-4b46-9ffd-91a1f2c9913b",
   "metadata": {},
   "source": [
    "# Proposal algorithm\n",
    "\n",
    "Let's make a proposal algorithm for the Spymaster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d795ca79-7be9-4c88-b789-8cb0b9ead3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "import nltk\n",
    "from string import ascii_lowercase\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626eb74d-9a4e-4d19-8385-dfca11675ec1",
   "metadata": {},
   "source": [
    "The `nltk` package has an english dictionary which can be downloaded via the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d214d1b-612f-4e74-923b-6176d390654b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\mattg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download english words\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1b4800c2-fab0-46e2-98fa-8c9bf2a611ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpyMaster:\n",
    "    \n",
    "    nlp = spacy.load('en_core_web_lg')\n",
    "    english_words = set([word.upper() for word in nltk.corpus.words.words()])\n",
    "    vocab = set([word.upper() for word in nlp.vocab.strings]).intersection(english_words)\n",
    "    \n",
    "    @classmethod\n",
    "    def set_vocab(cls, possible_words: set) -> None:\n",
    "        cls.vocab = list(set([word.upper() for word in cls.nlp.vocab.strings if word in possible_words]))\n",
    "    \n",
    "    def __init__(self, board_dict: dict, my_team: str, alpha: float = 0.01) -> None: \n",
    "        \n",
    "#     Arguments\n",
    "#     ------------\n",
    "#     board_dict : dictionary of the form {'blue': ..., 'orange': ..., 'black': ..., 'orange': ...} with lists of words under each team\n",
    "#     my_team : string, which team the bot is on (should be a key in board_dict)\n",
    "#     beta : scoring model parameter beta\n",
    "#     alpha : scoring model parameter alpha\n",
    "        \n",
    "        if my_team not in board_dict:\n",
    "            raise ValueError('Argument \"my_team\" should be a key in the dictionary argument \"board_dict\"')\n",
    "        \n",
    "        # convert all letters to uppercase when setting instance board words variable\n",
    "        self.board_dict = {team: [word.upper() for word in words] for team, words in board_dict.items()}\n",
    "        \n",
    "        # concatenate all board words into a single list\n",
    "        self.board_words = []\n",
    "        i = 0\n",
    "        for team, words in self.board_dict.items():\n",
    "            # get the indices in the \"all_board_words\" list that correspond to words in the bot's team\n",
    "            if team == my_team:\n",
    "                self.team_word_indices = np.arange(start = i, stop = len(words))\n",
    "            self.board_words.extend(words)\n",
    "            i += len(words)\n",
    "            \n",
    "        # get list of all possible proposal words\n",
    "        self.proposal_words = list(self.vocab.difference(self.board_words))\n",
    "            \n",
    "        # initialise spacy NLP instances\n",
    "        board_word_nlp = SpyMaster.nlp.pipe(self.board_words)\n",
    "        proposal_word_nlp = SpyMaster.nlp.pipe(self.proposal_words)\n",
    "        \n",
    "        # get embeddings for words on the borm\n",
    "        self.board_embeddings = np.array([word.vector for word in board_word_nlp])\n",
    "        # calculate L2 norms for board word embeddings\n",
    "        board_embedding_norms = np.linalg.norm(self.board_embeddings, axis = 1, ord = 2)\n",
    "        # norm everything to 1\n",
    "        self.board_embeddings = self.board_embeddings / board_embedding_norms[:, None]\n",
    "        \n",
    "        # get proposal word embeddings, calculate norms\n",
    "        self.proposal_embeddings = np.array([word.vector for word in proposal_word_nlp])\n",
    "        proposal_embedding_norms = np.linalg.norm(self.proposal_embeddings, axis = 1, ord = 2)\n",
    "        # remove words with zero-norm embeddings\n",
    "        nonzero_norm_mask = proposal_embedding_norms != 0\n",
    "        self.proposal_embeddings = self.proposal_embeddings[nonzero_norm_mask]\n",
    "        self.proposal_embeddings = self.proposal_embeddings / proposal_embedding_norms[nonzero_norm_mask, None]\n",
    "        self.proposal_words = np.array(self.proposal_words)[nonzero_norm_mask].tolist()\n",
    "        \n",
    "        # get cosine similarity between words on the board and all possible proposals\n",
    "        self.proposal_board_similarities = self.proposal_embeddings @ self.board_embeddings.T\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        \n",
    "        self.my_team_score = 0\n",
    "        self.other_team_score = 0\n",
    "        \n",
    "    def make_proposal(self) -> str:\n",
    "        \n",
    "        best_combination_score = 0\n",
    "        # loop through possible numbers of words to propose\n",
    "        for num_words in range(1, len(self.team_word_indices) + 1):\n",
    "            # loop through unique combinations of those words\n",
    "            for comb in combinations(self.team_word_indices, num_words):\n",
    "                # get distances between all words in the vocabulary and words in the combination\n",
    "                combination_similarities = self.proposal_board_similarities[:, comb]\n",
    "                # get the mean similarity between each word in the vocab and all words in the combination\n",
    "                combination_mean_similarities = combination_similarities.mean(axis = 1) \n",
    "                # get score ratio component of the final proposal score\n",
    "                team_score_ratio = self.alpha * (self.other_team_score + 1) / (self.my_team_score + 1)\n",
    "                # get scores for each proposal\n",
    "                proposal_scores = combination_mean_similarities + (team_score_ratio * num_words)\n",
    "                highest_score_idx = np.argmax(proposal_scores)\n",
    "                highest_score = proposal_scores[highest_score_idx]\n",
    "                # if the best score is higher than the best score seen so far, save the highest scoring word\n",
    "                if highest_score > best_combination_score:\n",
    "                    best_combination_score = highest_score\n",
    "                    target_words = [word for i, word in enumerate(self.board_words) if i in comb]\n",
    "                    highest_score_word = self.proposal_words[highest_score_idx]\n",
    "                    \n",
    "        return target_words, highest_score_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f29a5e11-802c-4738-97d9-743398f68964",
   "metadata": {},
   "outputs": [],
   "source": [
    "board = {'blue': ['STEEL', 'CHURCHILL', 'OPERA', 'BULB', 'NOTRE DAME', 'PASTE', 'HEAD', 'FIELD'],\n",
    "         'orange': ['COVER', 'SATURN', 'COLOSSEUM', 'PEARL', 'CLEOPATRA', 'NYLON', 'MARIE CURIE', 'GEAR'],\n",
    "         'white': ['UNICORN', 'HELMET', 'GATES', 'SPRAY', 'SPINE', 'SILK', 'ROAD', 'COUNTRY'],\n",
    "         'black': ['STRING']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d1d90477-6071-4ad9-a036-52b1ece9171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spymaster = SpyMaster(board, my_team = 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7f163219-3e3d-4bba-80ea-b5e6e83f6d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['STEEL'], 'STAINLESS')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spymaster.make_proposal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5093c6f-b6a5-4289-960d-01b4ee1337ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
