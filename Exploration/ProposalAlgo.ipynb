{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb28dafa-752d-4b46-9ffd-91a1f2c9913b",
   "metadata": {},
   "source": [
    "# Proposal algorithm\n",
    "\n",
    "Let's make a proposal algorithm for the Spymaster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d795ca79-7be9-4c88-b789-8cb0b9ead3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "import nltk\n",
    "from itertools import combinations, chain\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626eb74d-9a4e-4d19-8385-dfca11675ec1",
   "metadata": {},
   "source": [
    "The `nltk` package has an english dictionary which can be downloaded via the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "884a50fe-df48-4be9-bbb4-691b327041e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(chain(*[[1,2], [3,4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d214d1b-612f-4e74-923b-6176d390654b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\mattg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download english words\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1b4800c2-fab0-46e2-98fa-8c9bf2a611ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SpyMaster:\n",
    "    \n",
    "    nlp = spacy.load('en_core_web_lg')\n",
    "    english_words = set([word.upper() for word in nltk.corpus.words.words()])\n",
    "    vocab = set([word.upper() for word in nlp.vocab.strings]).intersection(english_words)\n",
    "    \n",
    "    @classmethod\n",
    "    def set_vocab(cls, \n",
    "                  possible_words: set) -> None:\n",
    "        \n",
    "        cls.vocab = set([word.upper() for word in cls.nlp.vocab.strings if word in possible_words])\n",
    "    \n",
    "    def __init__(self, \n",
    "                 board_dict: dict, \n",
    "                 my_team: str, \n",
    "                 alpha1: float = 1,\n",
    "                 alpha2: float = 1,\n",
    "                 alpha3: float = 0.5, \n",
    "                 alpha4: float = 0.5,\n",
    "                 alpha5: float = 0.5) -> None: \n",
    "        \n",
    "#     Arguments\n",
    "#     ------------\n",
    "#     board_dict : dictionary of the form {'blue': ..., 'orange': ..., 'black': ..., 'orange': ...} with lists of words under each team\n",
    "#     my_team : string, which team the bot is on (should be a key in board_dict)\n",
    "#     beta : scoring model parameter beta\n",
    "#     alpha : scoring model parameter alpha\n",
    "        \n",
    "        if my_team not in board_dict or (my_team != 'blue' and my_team != 'orange'):\n",
    "            raise ValueError('Argument \"my_team\" should be a key in the dictionary argument \"board_dict\", and one of (blue, orange)')\n",
    "        \n",
    "        # convert all letters to uppercase when setting instance board words variable\n",
    "        self.board_dict = {team: [word.upper() for word in words] for team, words in board_dict.items()}\n",
    "        \n",
    "        # concatenate all board words into a single list\n",
    "        self.board_words = list(chain(*self.board_dict.values()))\n",
    "        self.individual_board_words = list(chain(*[word.split(' ') for word in self.board_words]))\n",
    "           \n",
    "        self.team_word_indices = [i for i, word in enumerate(self.board_words) if word in self.board_dict[my_team]]\n",
    "        self.non_team_word_indices = [i for i, word in enumerate(self.board_words) if word not in self.board_dict[my_team]]\n",
    "        self.black_word_index = [i for i, word in enumerate(self.board_words) if word in self.board_dict['black']]\n",
    "            \n",
    "        # get list of all possible proposal words\n",
    "        \n",
    "        self.proposal_words = list(self.vocab.difference(self.individual_board_words))\n",
    "            \n",
    "        # initialise spacy NLP instances\n",
    "        board_word_nlp = SpyMaster.nlp.pipe(self.board_words)\n",
    "        proposal_word_nlp = SpyMaster.nlp.pipe(self.proposal_words)\n",
    "        \n",
    "        # get embeddings for words on the board\n",
    "        self.board_embeddings = np.array([word.vector for word in board_word_nlp])\n",
    "        # calculate L2 norms for board word embeddings\n",
    "        board_embedding_norms = np.linalg.norm(self.board_embeddings, axis = 1, ord = 2)\n",
    "        # norm everything to 1\n",
    "        self.board_embeddings = self.board_embeddings / board_embedding_norms[:, None]\n",
    "        \n",
    "        # get proposal word embeddings, calculate norms\n",
    "        self.proposal_embeddings = np.array([word.vector for word in proposal_word_nlp])\n",
    "        proposal_embedding_norms = np.linalg.norm(self.proposal_embeddings, axis = 1, ord = 2)\n",
    "        # remove words with zero-norm embeddings\n",
    "        nonzero_norm_mask = proposal_embedding_norms != 0\n",
    "        self.proposal_embeddings = self.proposal_embeddings[nonzero_norm_mask]\n",
    "        self.proposal_embeddings = self.proposal_embeddings / proposal_embedding_norms[nonzero_norm_mask, None]\n",
    "        self.proposal_words = np.array(self.proposal_words)[nonzero_norm_mask].tolist()\n",
    "        \n",
    "        # get cosine similarity between words on the board and all possible proposals\n",
    "        self.proposal_board_similarities = self.proposal_embeddings @ self.board_embeddings.T\n",
    "        \n",
    "        self.alpha1 = alpha1\n",
    "        self.alpha2 = alpha2\n",
    "        self.alpha3 = alpha3\n",
    "        self.alpha4 = alpha4\n",
    "        self.alpha5 = alpha5\n",
    "        \n",
    "        self.my_team_score = 0\n",
    "        self.other_team_score = 0\n",
    "        \n",
    "    def make_proposal(self) -> tuple:\n",
    "        \n",
    "        best_combination_score = 0\n",
    "        # loop through possible numbers of words to propose\n",
    "        for num_words in range(1, len(self.team_word_indices) + 1):\n",
    "            # loop through unique combinations of those words\n",
    "            for comb in combinations(self.team_word_indices, num_words):\n",
    "                # get scores for each proposal\n",
    "                proposal_scores = self.score(comb)\n",
    "                highest_score_idx = np.argmax(proposal_scores)\n",
    "                highest_score = proposal_scores[highest_score_idx]\n",
    "                # if the best score is higher than the best score seen so far, save the highest scoring word\n",
    "                if highest_score > best_combination_score:\n",
    "                    best_combination_score = highest_score\n",
    "                    target_words = [word for i, word in enumerate(self.board_words) if i in comb]\n",
    "                    highest_score_word = self.proposal_words[highest_score_idx]\n",
    "                    \n",
    "        return target_words, highest_score_word\n",
    "    \n",
    "    def score(self, targets):\n",
    "        \n",
    "        target_similarities = self.proposal_board_similarities[:, targets]\n",
    "        non_team_word_similarities = np.delete(self.proposal_board_similarities, targets, axis = 1)\n",
    "        mean_target_similarities = target_similarities.mean(axis = 1)\n",
    "        mean_non_team_word_similarities = non_team_word_similarities.mean(axis = 1)\n",
    "        var_non_team_word_similarities = (non_team_word_similarities**2).mean(axis = 1)\n",
    "        black_word_similarities = self.proposal_board_similarities[:, self.black_word_index[0]]\n",
    "        team_score_ratio = (self.other_team_score + 1) / (self.my_team_score + 1)\n",
    "        scores = (self.alpha1 * mean_target_similarities + \n",
    "                  self.alpha2 * team_score_ratio * np.exp(-1 / len(targets)) -\n",
    "                  self.alpha3 * mean_non_team_word_similarities -\n",
    "                  self.alpha4 * var_non_team_word_similarities -\n",
    "                  self.alpha5 * black_word_similarities)\n",
    "        return scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f29a5e11-802c-4738-97d9-743398f68964",
   "metadata": {},
   "outputs": [],
   "source": [
    "board = {'blue': ['STEEL', 'CHURCHILL', 'OPERA', 'BULB', 'NOTRE DAME', 'PASTE', 'HEAD', 'FIELD'],\n",
    "         'orange': ['COVER', 'SATURN', 'COLOSSEUM', 'PEARL', 'CLEOPATRA', 'NYLON', 'MARIE CURIE', 'GEAR'],\n",
    "         'white': ['UNICORN', 'HELMET', 'GATES', 'SPRAY', 'SPINE', 'SILK', 'ROAD', 'COUNTRY'],\n",
    "         'black': ['STRING']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d1d90477-6071-4ad9-a036-52b1ece9171b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.33254861831665"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "spymaster = SpyMaster(board, my_team = 'blue')\n",
    "time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7f163219-3e3d-4bba-80ea-b5e6e83f6d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['STEEL'], 'STAINLESS')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spymaster.make_proposal()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
